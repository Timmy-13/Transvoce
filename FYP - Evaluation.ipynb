{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________________\n",
      "INPUT WAVEFORM :  torch.Size([1, 29063])\n",
      "______________________________________________________________________________________\n",
      "\n",
      "______________________________________________________________________________________\n",
      "APPLIED MEL SPECTOGRAM :  torch.Size([1, 1, 128, 146])\n",
      "______________________________________________________________________________________\n",
      "\n",
      "______________________________________________________________________________________\n",
      "APPLIED SPEC AUGMENT :  torch.Size([1, 1, 128, 146])\n",
      "______________________________________________________________________________________\n",
      "\n",
      "______________________________________________________________________________________\n",
      "IN ENCODER : CONVOLUTION + SUBSAMPLED :  torch.Size([1, 35, 4464])\n",
      "______________________________________________________________________________________\n",
      "\n",
      "______________________________________________________________________________________\n",
      "IN ENCODER : LINEAR TRANSFORMATION :  torch.Size([1, 35, 144])\n",
      "______________________________________________________________________________________\n",
      "\n",
      "______________________________________________________________________________________\n",
      "IN CONFORMER BLOCK : FIRST FFN torch.Size([1, 35, 144])\n",
      "______________________________________________________________________________________\n",
      "\n",
      "______________________________________________________________________________________\n",
      "IN CONFORMER BLOCK : ATTENTION torch.Size([1, 35, 144])\n",
      "______________________________________________________________________________________\n",
      "\n",
      "______________________________________________________________________________________\n",
      "IN CONFORMER BLOCK : CONVOLUTION torch.Size([1, 35, 144])\n",
      "______________________________________________________________________________________\n",
      "\n",
      "______________________________________________________________________________________\n",
      "IN CONFORMER BLOCK : SECOND FFN torch.Size([1, 35, 144])\n",
      "______________________________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from torchaudio.transforms import TimeMasking, FrequencyMasking\n",
    "import torchaudio.transforms as T\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, d):\n",
    "    return val if exists(val) else d\n",
    "\n",
    "def calc_same_padding(kernel_size):\n",
    "    pad = kernel_size // 2\n",
    "    return (pad, pad - (kernel_size + 1) % 2)\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * x.sigmoid()\n",
    "\n",
    "class GLU(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, gate = x.chunk(2, dim=self.dim)\n",
    "        return out * gate.sigmoid()\n",
    "\n",
    "class DepthWiseConv1d(nn.Module):\n",
    "    def __init__(self, chan_in, chan_out, kernel_size, padding):\n",
    "        super().__init__()\n",
    "        self.padding = padding\n",
    "        self.conv = nn.Conv1d(chan_in, chan_out, kernel_size, groups = chan_in)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.pad(x, self.padding)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Scale(nn.Module):\n",
    "    def __init__(self, scale, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(x, **kwargs) * self.scale\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x, **kwargs)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        heads = 4,\n",
    "        dim_head = 36,\n",
    "        dropout = 0.,\n",
    "        max_pos_emb = 512\n",
    "    ):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads # 36 * 4\n",
    "        self.heads= heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.to_q = nn.Linear(dim, inner_dim, bias = False)\n",
    "        self.to_kv = nn.Linear(dim, inner_dim * 2, bias = False)\n",
    "        self.to_out = nn.Linear(inner_dim, dim)\n",
    "\n",
    "        self.max_pos_emb = max_pos_emb\n",
    "        self.rel_pos_emb = nn.Embedding(2 * max_pos_emb + 1, dim_head)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        context = None,\n",
    "        mask = None,\n",
    "        context_mask = None\n",
    "    ):\n",
    "        n, device, h, max_pos_emb, has_context = x.shape[-2], x.device, self.heads, self.max_pos_emb, exists(context)\n",
    "        context = default(context, x)\n",
    "\n",
    "        q, k, v = (self.to_q(x), *self.to_kv(context).chunk(2, dim = -1))\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), (q, k, v))\n",
    "\n",
    "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "\n",
    "        # shaw's relative positional embedding\n",
    "\n",
    "        seq = torch.arange(n, device = device)\n",
    "        dist = rearrange(seq, 'i -> i ()') - rearrange(seq, 'j -> () j')\n",
    "        dist = dist.clamp(-max_pos_emb, max_pos_emb) + max_pos_emb\n",
    "        rel_pos_emb = self.rel_pos_emb(dist).to(q)\n",
    "        pos_attn = einsum('b h n d, n r d -> b h n r', q, rel_pos_emb) * self.scale\n",
    "        dots = dots + pos_attn\n",
    "\n",
    "        if exists(mask) or exists(context_mask):\n",
    "            mask = default(mask, lambda: torch.ones(*x.shape[:2], device = device))\n",
    "            context_mask = default(context_mask, mask) if not has_context else default(context_mask, lambda: torch.ones(*context.shape[:2], device = device))\n",
    "            mask_value = -torch.finfo(dots.dtype).max\n",
    "            mask = rearrange(mask, 'b i -> b () i ()') * rearrange(context_mask, 'b j -> b () () j')\n",
    "            dots.masked_fill_(~mask, mask_value)\n",
    "\n",
    "        attn = dots.softmax(dim = -1)\n",
    "\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        out = self.to_out(out)  # W0\n",
    "        return self.dropout(out)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        mult = 4,\n",
    "        dropout = 0.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, dim * mult), # 35*144 into 35*576\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim * mult, dim), #reverse\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class ConformerConvModule(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        causal = False,\n",
    "        expansion_factor = 2,\n",
    "        kernel_size = 32,\n",
    "        dropout = 0.\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        inner_dim = dim * expansion_factor\n",
    "        padding = calc_same_padding(kernel_size) if not causal else (kernel_size - 1, 0)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            Rearrange('b n c -> b c n'),\n",
    "            nn.Conv1d(dim, inner_dim * 2, 1),\n",
    "            GLU(dim=1),\n",
    "            DepthWiseConv1d(inner_dim, inner_dim, kernel_size = kernel_size, padding = padding),\n",
    "            nn.BatchNorm1d(inner_dim) if not causal else nn.Identity(),\n",
    "            Swish(),\n",
    "            nn.Conv1d(inner_dim, dim, 1),\n",
    "            Rearrange('b c n -> b n c'),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Conformer Block\n",
    "\n",
    "class ConformerBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        dim,\n",
    "        dim_head = 64,\n",
    "        heads = 8,\n",
    "        ff_mult = 4,\n",
    "        conv_expansion_factor = 2,\n",
    "        conv_kernel_size = 31,\n",
    "        attn_dropout = 0.,\n",
    "        ff_dropout = 0.,\n",
    "        conv_dropout = 0.,\n",
    "        conv_causal = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.ff1 = FeedForward(dim = dim, mult = ff_mult, dropout = ff_dropout)\n",
    "        self.attn = Attention(dim = dim, dim_head = dim_head, heads = heads, dropout = attn_dropout)\n",
    "        self.conv = ConformerConvModule(dim = dim, causal = conv_causal, expansion_factor = conv_expansion_factor, kernel_size = conv_kernel_size, dropout = conv_dropout)\n",
    "        self.ff2 = FeedForward(dim = dim, mult = ff_mult, dropout = ff_dropout)\n",
    "\n",
    "        self.attn = PreNorm(dim, self.attn)\n",
    "        self.ff1 = Scale(0.5, PreNorm(dim, self.ff1))\n",
    "        self.ff2 = Scale(0.5, PreNorm(dim, self.ff2))\n",
    "\n",
    "        self.post_norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        x = self.ff1(x) + x\n",
    "        print(\"______________________________________________________________________________________\")\n",
    "        print(f\"IN CONFORMER BLOCK : FIRST FFN\", x.shape)\n",
    "        print(\"______________________________________________________________________________________\\n\")\n",
    "        x = self.attn(x, mask = mask) + x\n",
    "        print(\"______________________________________________________________________________________\")\n",
    "        print(f\"IN CONFORMER BLOCK : ATTENTION\", x.shape)\n",
    "        print(\"______________________________________________________________________________________\\n\")\n",
    "        x = self.conv(x) + x\n",
    "        print(\"______________________________________________________________________________________\")\n",
    "        print(f\"IN CONFORMER BLOCK : CONVOLUTION\", x.shape)\n",
    "        print(\"______________________________________________________________________________________\\n\")\n",
    "        x = self.ff2(x) + x\n",
    "        print(\"______________________________________________________________________________________\")\n",
    "        print(f\"IN CONFORMER BLOCK : SECOND FFN\", x.shape)\n",
    "        print(\"______________________________________________________________________________________\\n\")\n",
    "        x = self.post_norm(x)\n",
    "        return x\n",
    "\n",
    "# Conformer\n",
    "\n",
    "class Conformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        *,\n",
    "        depth,\n",
    "        dim_head = 64,\n",
    "        heads = 4,\n",
    "        ff_mult = 4,\n",
    "        conv_expansion_factor = 2,\n",
    "        conv_kernel_size = 32,\n",
    "        attn_dropout = 0.,\n",
    "        ff_dropout = 0.,\n",
    "        conv_dropout = 0.,\n",
    "        conv_causal = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.layers = nn.ModuleList([])\n",
    "\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(ConformerBlock(\n",
    "                dim = dim,\n",
    "                dim_head = dim_head,\n",
    "                heads = heads,\n",
    "                ff_mult = ff_mult,\n",
    "                conv_expansion_factor = conv_expansion_factor,\n",
    "                conv_kernel_size = conv_kernel_size,\n",
    "                conv_causal = conv_causal\n",
    "\n",
    "            ))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        for block in self.layers:\n",
    "            x = block(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# SpecAugment Module\n",
    "class SpecAugment(nn.Module):\n",
    "    def __init__(self, freq_blocks=2, time_blocks=10, \n",
    "                 freq_block_ratio=0.33, time_block_ratio=0.05):\n",
    "        super().__init__()\n",
    "        self.freq_blocks = freq_blocks\n",
    "        self.time_blocks = time_blocks\n",
    "        self.freq_block_ratio = freq_block_ratio\n",
    "        self.time_block_ratio = time_block_ratio\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, _, freq_bins, time_steps = x.shape  # Get spectrogram shape\n",
    "\n",
    "        # Apply frequency masking\n",
    "        for _ in range(self.freq_blocks):\n",
    "            max_length = int(freq_bins * self.freq_block_ratio)\n",
    "            x = T.FrequencyMasking(max_length)(x)\n",
    "\n",
    "        # Apply time masking\n",
    "        for _ in range(self.time_blocks):\n",
    "            max_length = int(time_steps * self.time_block_ratio)\n",
    "            x = T.TimeMasking(max_length)(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Convolutional Subsampling Module\n",
    "class ConvSubsampling(nn.Module):\n",
    "    def __init__(self, out_channels, in_channels=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)  # Shape: (B, C, H, W) -> (B, C, H/4, W/4)\n",
    "        b, c, h, w = x.shape\n",
    "        x = x.permute(0,3,1,2)\n",
    "        x = x.contiguous().view(b, w, c*h)  # Reshape for Transformer input\n",
    "        return x\n",
    "\n",
    "class FullConformer(nn.Module):\n",
    "    def __init__(self, *, dim, depth):\n",
    "        super().__init__()\n",
    "        self.spec_augment = SpecAugment()\n",
    "        self.subsampling = ConvSubsampling(in_channels=1, out_channels=dim)\n",
    "\n",
    "        self.linear = nn.Linear(dim*((128-1)//4), dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        self.conformer = Conformer(\n",
    "            dim=dim,\n",
    "            depth=depth,\n",
    "            dim_head=36,\n",
    "            heads=4,\n",
    "            ff_mult=4,\n",
    "            conv_expansion_factor=2,\n",
    "            conv_kernel_size=32,\n",
    "            attn_dropout=0.1,\n",
    "            ff_dropout=0.1,\n",
    "            conv_dropout=0.1,\n",
    "            conv_causal=False\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.spec_augment(x)\n",
    "        print(\"______________________________________________________________________________________\")\n",
    "        print(f\"APPLIED SPEC AUGMENT : \", x.shape)\n",
    "        print(\"______________________________________________________________________________________\\n\")\n",
    "        x = self.subsampling(x)  \n",
    "        print(\"______________________________________________________________________________________\")\n",
    "        print(f\"IN ENCODER : CONVOLUTION + SUBSAMPLED : \", x.shape)\n",
    "        print(\"______________________________________________________________________________________\\n\")\n",
    "        x = self.linear(x)\n",
    "        print(\"______________________________________________________________________________________\")\n",
    "        print(f\"IN ENCODER : LINEAR TRANSFORMATION : \", x.shape)\n",
    "        print(\"______________________________________________________________________________________\\n\")\n",
    "        x = self.dropout(x)       \n",
    "        x = self.conformer(x)     \n",
    "        return x\n",
    "    \n",
    "\n",
    "# Load and preprocess audio\n",
    "waveform, sample_rate = torchaudio.load(\"src.wav\")\n",
    "\n",
    "# Ensure the sample rate is 16,000 Hz\n",
    "if sample_rate != 16000:\n",
    "    resampler = T.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "    waveform = resampler(waveform)\n",
    "    sample_rate = 16000\n",
    "\n",
    "print(\"______________________________________________________________________________________\")\n",
    "print(f\"INPUT WAVEFORM : \", waveform.shape)\n",
    "print(\"______________________________________________________________________________________\\n\")\n",
    "\n",
    "# Mel spectrogram parameters\n",
    "mel_spectrogram = T.MelSpectrogram(\n",
    "    sample_rate=sample_rate,\n",
    "    n_mels=128,         # 128 Mel channels\n",
    "    n_fft=int(0.050 * sample_rate),  # Frame size = 50ms\n",
    "    hop_length=int(0.0125 * sample_rate),  # Frame step = 12.5ms\n",
    "    f_min=20,           # Lower band = 20 Hz\n",
    "    f_max=8000          # Upper band = 8000 Hz\n",
    ")\n",
    "\n",
    "# Convert to mono & compute Mel spectrogram\n",
    "spec = mel_spectrogram(waveform.mean(dim=0, keepdim=True))\n",
    "spec = (spec - spec.mean()) / spec.std()  # Normalize\n",
    "spec = spec.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "print(\"______________________________________________________________________________________\")\n",
    "print(f\"APPLIED MEL SPECTOGRAM : \", spec.shape)\n",
    "print(\"______________________________________________________________________________________\\n\")\n",
    "\n",
    "# Define and run model\n",
    "model = FullConformer(dim=144, depth=16)\n",
    "output = model(spec)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
